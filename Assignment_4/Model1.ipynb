{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def printIMG(x,y, idx):\n",
    "    label_dict = {\n",
    " 0: 'T-shirt/top',\n",
    " 1: 'Trouser',\n",
    " 2: 'Pullover',\n",
    " 3: 'Dress',\n",
    " 4: 'Coat',\n",
    " 5: 'Sandal',\n",
    " 6: 'Shirt',\n",
    " 7: 'Sneaker',\n",
    " 8: 'Bag',\n",
    " 9: 'Ankle boot',\n",
    "}\n",
    "\n",
    "    plt.imshow(x[idx])\n",
    "    plt.xlabel(label_dict[idx])\n",
    "# plt.imshow(x[0])\n",
    "\n",
    "def preprocessing():\n",
    "    (x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data() #tf.keras.datasets.mnist.load_data(path=\"mnist.npz\") # \n",
    "    x_train =x_train/255  #np.reshape(x_train, (x_train.shape[0], 784))/255.\n",
    "    x_test = x_test/255 #np.reshape(x_test, (x_test.shape[0], 784))/255.\n",
    "    y_train = tf.keras.utils.to_categorical(y_train)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "    x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "    # x_train=  tf.cast( tf.expand_dims(x_train,-1), dtype= tf.float32, name=None) \n",
    "    # x_test=  tf.cast( tf.expand_dims(tf.expand_dims(x_test,-1),-1), dtype= tf.float32, name=None) \n",
    "\n",
    "    # x_train= tf.image.grayscale_to_rgb(x_train, name=None)\n",
    "    # x_test= tf.image.grayscale_to_rgb(x_test, name=None)\n",
    "\n",
    "    # print(x_train.shape)\n",
    "    # print(x_train.shape)\n",
    "    # output =[]\n",
    "    # for t in data:\n",
    "    #     if(len(t)>1):\n",
    "    #         for d in t:\n",
    "    #             d = d/d.max()\n",
    "    #             output.append(d.reshape(d.shape[0],-1))\n",
    "    #     else:\n",
    "    #         d = d/d.max()\n",
    "    #         output.append(output.append(d.reshape(d.shape[0],-1)))\n",
    "    \n",
    "    return (x_train, y_train, x_test, y_test)\n",
    "\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self, num_input, layers ,lr, dropout, debug=False):\n",
    "        self.hiddenlayers =layers\n",
    "        self.num_features = layers[0]\n",
    "        self.num_classes = layers[-1]\n",
    "        self.L =  len(layers) #len(self.Weights)+1  # len(layers)\n",
    "\n",
    "        self.debug = debug\n",
    "\n",
    "        self.lr = lr\n",
    "        self.drouput = dropout\n",
    "\n",
    "        # paramerters\n",
    "        self.Weights = {}\n",
    "        self.biases = {}\n",
    "        self.dw = {}\n",
    "        self.db = {}\n",
    "\n",
    "        # thins that we can ply with are ###\n",
    "        # pooling\n",
    "        # stride\n",
    "        #perhaps more\n",
    "        # ###\n",
    "\n",
    "\n",
    "        # should happen at the beginning when initlizing the \n",
    "        self.initilizeWeight()\n",
    "\n",
    "    def initilizeWeight(self):\n",
    "        # print(\"initilizeWeight\")\n",
    "        for i in range(1, self.L-1):\n",
    "            \n",
    "            self.Weights[i] =  self.hiddenlayers[i]#tf.Variable(tf.random.normal(shape =(self.hiddenlayers[i], self.hiddenlayers[i-1]))) #, initializer =  tf.contrib.layers.xavier_initializer(seed = 0)))\n",
    "            if self.debug: print(f\"self.Weights[i].shape: {self.Weights[i]} \")\n",
    "        # \n",
    "        #   self.biases[i] = tf.Variable(tf.random.normal(shape = (self.hiddenlayers[i], 1)))\n",
    "\n",
    "            # self.Weights[1] = tf.compat.v1.get_variable(\"W1\", [5,5, 3, 5], initializer =  tf.keras.initializers.glorot_normal(seed = 0)) # tf.nn.conv2d\n",
    "            # self.Weights[2] = tf.compat.v1.get_variable(\"W2\", [3,3, 5, 10], initializer =  tf.keras.initializers.glorot_normal(seed = 0)) # , 8, 16\n",
    "\n",
    "            # self.biases[1] = tf.Variable(tf.random.normal(shape = (self.hiddenlayers[i], 1)))\n",
    "            # self.biases[2] = tf.Variable(tf.random.normal(shape = (self.hiddenlayers[i], 1)))\n",
    "\n",
    "\n",
    "\n",
    "    def compute_loss(self, A, Y):\n",
    "        # print(\"compute_loss\")\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(Y,A)\n",
    "        # why reduce mean\n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "    def forwardpass(self, X):\n",
    "        # print(\"forwardpass\")\n",
    "\n",
    "        # s = [8,4]\n",
    "        # f =[8,4]\n",
    "        if self.debug: print(f\"self.Weights: {len(self.Weights)}\")\n",
    "\n",
    "        \n",
    "        A = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        for i in range(1, len(self.Weights)+1):\n",
    "\n",
    "            # Z = tf.matmul(A,tf.transpose(self.Weights[i])) + tf.transpose(self.biases[i])\n",
    "            # print(i)\n",
    "            # input()\n",
    "            if self.debug: \n",
    "                print(f\" {i} {self.Weights[i].shape} \")  \n",
    "                input()\n",
    "            \n",
    "           \n",
    "            Z = tf.nn.conv2d(A, self.Weights[i], strides = [1,1,1,1], padding = 'SAME')\n",
    "            A = tf.nn.relu(Z)\n",
    " \n",
    "            A = tf.nn.max_pool(A, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "\n",
    "            # # print(f\"Z: {Z.shape}\")\n",
    "            # if i != len(self.Weights):\n",
    "            #     A = tf.nn.relu(Z)\n",
    " \n",
    "            #     A = tf.nn.max_pool(A, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "            # else:\n",
    "            #     # input()\n",
    "            #     # input()\n",
    "            #     # print(\"Before f\")\n",
    "            #     input()\n",
    "            #     F = tf.compat.v1.layers.flatten(Z)\n",
    "            #     # f = tf.keras.Fl\n",
    "            #     # print(\"After f\")\n",
    "\n",
    "            #     # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "            #     # 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "            #     # print(\"Before Z3\")\n",
    "\n",
    "            #     Z3 = tf.compat.v1.layers.dense(F, self.num_classes, activation=None)   #, activation_fn=None\n",
    "\n",
    "                # print(\"Before Z3\")\n",
    "\n",
    "                # print(f\"Z3: {Z3.shape}\")\n",
    "\n",
    "                # input()\n",
    "                # A = Z3\n",
    "            if self.debug: \n",
    "                input()\n",
    "        F = tf.compat.v1.layers.flatten(A)\n",
    "        # f = tf.keras.Fl\n",
    "        # print(\"After f\")\n",
    "\n",
    "        # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "        # 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "        # print(\"Before Z3\")\n",
    "\n",
    "        Z3 = tf.compat.v1.layers.dense(F, self.num_classes, activation=None)   \n",
    "\n",
    "        # print(\"Before Z3\")\n",
    "\n",
    "        # print(f\"Z3: {Z3.shape}\")\n",
    "\n",
    "        # input()\n",
    "        A = Z3    \n",
    "        return A\n",
    "\n",
    "\n",
    "    def updateParams(self):\n",
    "        \"\"\" \n",
    "        We have all the weights and biases. now we need to update the weights with gd\n",
    "        The formula is \n",
    "        \"\"\"\n",
    "        # print(\"updateParams\")\n",
    "\n",
    "        # check also with assignning sub\n",
    "        for i in range(1, len(self.Weights)):\n",
    "            self.Weights[i].assign_sub(self.lr * self.dw[i])\n",
    "            #self.biases[i].assign_sub(self.lr * self.db[i]) \n",
    "\n",
    "\n",
    "    def printInfoModel(self):\n",
    "        print(f\"Number of features: {self.num_features}\")\n",
    "        print(f\"Number of classes: {self.num_classes}\")\n",
    "        print(f\"Number of self.Weights {len(self.Weights)}\")\n",
    "\n",
    "\n",
    "        for i in range(1, len(self.hiddenlayers)-1):\n",
    "            print(f\"Hidden Layer {i}: {self.hiddenlayers[i].shape}\")\n",
    "\n",
    "\n",
    "    def computeLoss(self, Y, Z):\n",
    "        # print(\"compute_loss\")\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(Y, Z) # try to use softmax\n",
    "        print(f\"tf.reduce_mean(loss): {tf.reduce_mean(loss)}\")\n",
    "        input()\n",
    "        return (tf.reduce_mean(loss))\n",
    "\n",
    "\n",
    "    def train(self, x_train, y_train, x_test, y_test, epochs, steps_per_epoch, batch_size):\n",
    "\n",
    "        history = {\n",
    "            'val_loss':[],\n",
    "            'train_loss':[],\n",
    "            'val_acc':[]\n",
    "        }\n",
    "        \n",
    "        for e in range(0, epochs):\n",
    "            epoch_train_loss = 0.\n",
    "            print('Epoch{}'.format(e), end='.')\n",
    "            for i in range(0, steps_per_epoch):\n",
    "                x_batch = x_train[i*batch_size:(i+1)*batch_size]\n",
    "                y_batch = y_train[i*batch_size:(i+1)*batch_size]\n",
    "                \n",
    "                batch_loss = self.trainOnBatch(x_batch, y_batch)\n",
    "                epoch_train_loss += batch_loss\n",
    "                \n",
    "                if i%int(steps_per_epoch/10) == 0:\n",
    "                    print(end='.')\n",
    "                    \n",
    "            history['train_loss'].append(epoch_train_loss/steps_per_epoch)\n",
    "            val_A = self.forwardpass(x_test)\n",
    "            # print(\"val_A\")\n",
    "            # input()\n",
    "            val_loss = self.compute_loss(val_A, y_test).numpy()\n",
    "            history['val_loss'].append(val_loss)\n",
    "            val_preds = self.predict(x_test)\n",
    "            val_acc =    np.mean(np.argmax(y_test, axis=1) == val_preds.numpy())\n",
    "            history['val_acc'].append(val_acc)\n",
    "            print('Val acc:',val_acc)\n",
    "        return history\n",
    "\n",
    "    def dropout(self, X):\n",
    "        a = tf.random.uniform((X.shape[0], X.shape[1]), dtype=tf.dtypes.float32)\n",
    "        b = tf.where(a<self.drouput , 0,1)\n",
    "        b = tf.cast(b, tf.dtypes.float32)\n",
    "        return (tf.math.multiply(b,X))\n",
    "\n",
    "\n",
    "    def trainOnBatch(self, X, Y):\n",
    "\n",
    "        X = tf.convert_to_tensor(X, dtype = tf.float32)\n",
    "        Y = tf.convert_to_tensor(Y,dtype = tf.float32)\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            for i in range(1, len(self.Weights)):\n",
    "                if self.debug: print(f\"tape: {i}\")\n",
    "\n",
    "                #X = self.dropout(X)\n",
    "                Z = self.forwardpass(X)\n",
    "                \n",
    "                loss = self.computeLoss(Y, Z)\n",
    "                self.dw[i] = tape.gradient(loss, self.Weights[i])\n",
    "\n",
    "                if self.debug:\n",
    "                    print(f\"type(loss): {type(loss)}\")\n",
    "                    print(f\"type(Weights[i]): {type(self.Weights[i])}\")\n",
    "                    print(f\"type(self.dw[i]): {type(self.dw[i])}\")\n",
    "\n",
    "        del tape\n",
    "        self.updateParams()\n",
    "        return loss.numpy()\n",
    "\n",
    "    def predict(self, X):\n",
    "        A = self.forwardpass(X)\n",
    "        return tf.argmax(tf.nn.softmax(A), axis=1)\n",
    "        \n",
    "\n",
    "\n",
    "n_classes = 10\n",
    "n_Input = 784\n",
    "weights = [\n",
    "    n_Input,\n",
    "    tf.compat.v1.get_variable('W0', shape=(3,3,1,32), initializer=tf.keras.initializers.glorot_normal()),\n",
    "     tf.compat.v1.get_variable('W1', shape=(3,3,32,64), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    #  tf.compat.v1.get_variable('W2', shape=(3,3,64,128), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    #  tf.compat.v1.get_variable('W3', shape=(4*4*128,128), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    #  tf.compat.v1.get_variable('W6', shape=(64,n_classes), initializer=tf.keras.initializers.glorot_normal()),\n",
    "     n_classes,\n",
    "]\n",
    "\n",
    "\n",
    "net = CNN(n_Input,weights,3e-3, 0.3, debug = False)\n",
    "net.printInfoModel()\n",
    "\n",
    "\n",
    "\n",
    "(x_train, y_train, x_test, y_test) = preprocessing()\n",
    "\n",
    "batch_size = 120\n",
    "epochs = 25\n",
    "steps_per_epoch = int(x_train.shape[0]/batch_size)\n",
    "lr = 3e-3\n",
    "print('Steps per epoch', steps_per_epoch)\n",
    "\n",
    "\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "history = net.train(\n",
    "    x_train,y_train,\n",
    "    x_test, y_test,\n",
    "    epochs, steps_per_epoch,\n",
    "    batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def printIMG(x,y, idx):\n",
    "    label_dict = {\n",
    " 0: 'T-shirt/top',\n",
    " 1: 'Trouser',\n",
    " 2: 'Pullover',\n",
    " 3: 'Dress',\n",
    " 4: 'Coat',\n",
    " 5: 'Sandal',\n",
    " 6: 'Shirt',\n",
    " 7: 'Sneaker',\n",
    " 8: 'Bag',\n",
    " 9: 'Ankle boot',\n",
    "}\n",
    "\n",
    "    plt.imshow(x[idx])\n",
    "    plt.xlabel(label_dict[idx])\n",
    "# plt.imshow(x[0])\n",
    "\n",
    "def preprocessing():\n",
    "    (x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data() #tf.keras.datasets.mnist.load_data(path=\"mnist.npz\") # \n",
    "    x_train =x_train/255  #np.reshape(x_train, (x_train.shape[0], 784))/255.\n",
    "    x_test = x_test/255 #np.reshape(x_test, (x_test.shape[0], 784))/255.\n",
    "    y_train = tf.keras.utils.to_categorical(y_train)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "    x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "    # x_train=  tf.cast( tf.expand_dims(x_train,-1), dtype= tf.float32, name=None) \n",
    "    # x_test=  tf.cast( tf.expand_dims(tf.expand_dims(x_test,-1),-1), dtype= tf.float32, name=None) \n",
    "\n",
    "    # x_train= tf.image.grayscale_to_rgb(x_train, name=None)\n",
    "    # x_test= tf.image.grayscale_to_rgb(x_test, name=None)\n",
    "\n",
    "    # print(x_train.shape)\n",
    "    # print(x_train.shape)\n",
    "    # output =[]\n",
    "    # for t in data:\n",
    "    #     if(len(t)>1):\n",
    "    #         for d in t:\n",
    "    #             d = d/d.max()\n",
    "    #             output.append(d.reshape(d.shape[0],-1))\n",
    "    #     else:\n",
    "    #         d = d/d.max()\n",
    "    #         output.append(output.append(d.reshape(d.shape[0],-1)))\n",
    "    \n",
    "    return (x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 784\n",
      "Number of classes: 10\n",
      "Number of self.Weights 2\n",
      "Hidden Layer 1: (3, 3, 1, 32)\n",
      "Hidden Layer 2: (3, 3, 32, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18404\\2334764415.py:109: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  F = tf.compat.v1.layers.flatten(A)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18404\\2334764415.py:110: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  Z3 = tf.compat.v1.layers.dense(F, self.num_classes, activation=None)   #, activation_fn=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch 500\n",
      "Epoch0.A. shape 1: (120, 28, 28, 1)\n",
      "Z. tf.nn.conv2d shape 1: (120, 28, 28, 32)\n",
      "A. tf.nn.conv2d shape 1: (120, 28, 28, 32)\n",
      "A. tf.Max shape 1: (120, 14, 14, 32)\n",
      "A. shape 2: (120, 14, 14, 32)\n",
      "Z. tf.nn.conv2d shape 2: (120, 14, 14, 64)\n",
      "A. tf.nn.conv2d shape 2: (120, 14, 14, 64)\n",
      "A. tf.Max shape 2: (120, 7, 7, 64)\n",
      "A shape before flat: (120, 7, 7, 64)\n",
      "F shape: (120, 3136)\n",
      "tf.transpose(self.last_dense): (10, 120)\n",
      "self.last_dense: (120, 10)\n",
      "tf.reduce_mean(loss): 2.2894654273986816\n",
      "Computed Loss\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "self.dw[i]: (3, 3, 1, 32)\n",
      "<tf.Variable 'W0:0' shape=(3, 3, 1, 32) dtype=float32, numpy=\n",
      "array([[[[ 1.79153278e-01,  3.73674147e-02, -1.66934896e-02,\n",
      "           2.67169531e-02, -9.69971716e-02,  5.47048412e-02,\n",
      "          -3.82513441e-02,  1.24162465e-01,  1.23041756e-01,\n",
      "          -5.85910715e-02, -3.19107845e-02,  2.55337618e-02,\n",
      "          -7.69038945e-02, -2.19313856e-02,  3.11505627e-02,\n",
      "           7.64664263e-02, -4.69306745e-02, -1.97767410e-02,\n",
      "          -3.16265263e-02, -1.39655443e-02,  1.02642216e-02,\n",
      "          -1.17816031e-01, -2.53721774e-02,  8.85190666e-02,\n",
      "           2.03560740e-02, -4.27722596e-02, -4.55554947e-03,\n",
      "          -1.30701765e-01,  3.70251872e-02, -4.73563261e-02,\n",
      "           2.45620143e-02,  2.29167454e-02]],\n",
      "\n",
      "        [[ 3.00358050e-02, -1.95212883e-03, -1.69408638e-02,\n",
      "          -7.25636855e-02,  1.08787298e-01,  4.02575135e-02,\n",
      "          -9.03514773e-02,  8.87325034e-02, -4.75767106e-02,\n",
      "          -9.41139460e-02,  2.74176933e-02,  2.58951876e-02,\n",
      "          -1.25608250e-01, -6.69521466e-02,  4.17099856e-02,\n",
      "          -1.63828731e-01, -1.20228007e-01, -1.34557441e-01,\n",
      "          -6.39222711e-02,  4.18896042e-02, -1.13426829e-02,\n",
      "           1.71853858e-03, -7.90522248e-03,  3.59648429e-02,\n",
      "           1.51955718e-02,  9.80058610e-02,  3.13568674e-02,\n",
      "           2.62721954e-03,  3.50910388e-02,  6.04753681e-02,\n",
      "          -6.61517978e-02,  4.94801849e-02]],\n",
      "\n",
      "        [[ 4.61247284e-03, -1.39174163e-01,  1.35363728e-01,\n",
      "           8.82269144e-02,  7.26939877e-03,  5.69468662e-02,\n",
      "           1.05520613e-01,  1.94656663e-02, -9.00680646e-02,\n",
      "           1.28396049e-01,  1.26829028e-01,  1.05933324e-01,\n",
      "           1.26644626e-01,  4.88527678e-02,  6.89127808e-03,\n",
      "          -1.31089523e-01,  2.67564338e-02, -1.82796409e-03,\n",
      "          -7.80738965e-02, -1.48503363e-01,  1.32715702e-02,\n",
      "          -1.80433989e-01, -4.09666635e-02, -8.43629539e-02,\n",
      "           1.16998240e-01,  7.81515799e-03, -2.93553509e-02,\n",
      "          -4.75158393e-02, -6.29929407e-03,  7.19022974e-02,\n",
      "          -5.56090623e-02,  7.26236776e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 8.07572007e-02, -5.39373159e-02,  8.58039409e-02,\n",
      "           4.11057547e-02, -4.92029227e-02,  9.20820236e-02,\n",
      "           1.39130145e-01, -8.60134140e-02,  7.35021755e-02,\n",
      "           4.36185002e-02,  1.13048136e-01,  6.28437102e-02,\n",
      "           1.09014101e-01, -4.04711254e-02, -9.99546051e-02,\n",
      "           2.20927279e-02,  3.11438497e-02, -4.90589589e-02,\n",
      "          -9.47972685e-02,  3.52071375e-02, -1.76108517e-02,\n",
      "          -3.14045176e-02, -9.85096674e-03, -1.50683185e-03,\n",
      "          -3.00349686e-02, -1.07836105e-01, -2.68855821e-02,\n",
      "          -2.03980152e-02, -5.54154515e-02, -4.26869243e-02,\n",
      "           3.98496725e-02,  8.92059729e-02]],\n",
      "\n",
      "        [[-8.88190866e-02, -7.71934614e-02, -3.69732678e-02,\n",
      "           1.17966058e-02, -1.58346929e-02,  1.60378555e-03,\n",
      "           1.23404816e-01, -1.73109490e-02, -2.54453439e-02,\n",
      "          -8.51464495e-02, -6.32402897e-02,  1.27048001e-01,\n",
      "          -3.81517899e-03, -6.57963306e-02,  1.81885213e-01,\n",
      "          -1.21837899e-01, -5.50423451e-02,  1.15358736e-02,\n",
      "           1.30196854e-01,  4.22269385e-03,  1.09155588e-01,\n",
      "           4.03481983e-02,  7.26241805e-03,  6.43113777e-02,\n",
      "          -1.21938683e-01,  4.35242653e-02, -2.98052817e-03,\n",
      "          -6.26321509e-02, -1.05160944e-01, -9.19675156e-02,\n",
      "          -4.92693931e-02, -1.55786961e-01]],\n",
      "\n",
      "        [[ 2.97936872e-02, -1.28819253e-02,  1.20816089e-01,\n",
      "           1.82119057e-01,  1.12414770e-01, -8.19185749e-02,\n",
      "          -6.52795210e-02,  9.62207094e-02,  5.13680279e-02,\n",
      "           9.63405520e-03, -1.47779053e-02,  3.60904112e-02,\n",
      "          -1.34593412e-01, -1.61256328e-01, -2.82180589e-02,\n",
      "          -4.53757085e-02,  1.53136119e-01,  6.15646839e-02,\n",
      "           3.31223607e-02, -1.16755426e-01,  4.48172502e-02,\n",
      "           3.95690911e-02, -1.13276243e-01, -5.81010729e-02,\n",
      "          -6.92832768e-02,  1.50100014e-03, -1.03582107e-01,\n",
      "           1.02495931e-01, -5.64655550e-02, -1.08132601e-01,\n",
      "          -6.44335151e-02, -2.19964795e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 2.73629576e-02,  1.02770887e-02,  1.49440482e-01,\n",
      "           4.48107272e-02, -1.48801170e-02, -7.50967069e-04,\n",
      "           1.77986339e-01,  5.55767491e-03, -9.38866809e-02,\n",
      "          -1.00002885e-01,  2.54180972e-02, -7.91088715e-02,\n",
      "          -7.99914598e-02, -5.68461604e-02,  1.39959510e-02,\n",
      "           9.81397405e-02, -4.27078716e-02, -1.83043964e-02,\n",
      "           1.02953598e-01, -1.67429164e-01,  4.98738550e-02,\n",
      "          -2.42886338e-02,  7.89888352e-02,  4.99218628e-02,\n",
      "           1.15852587e-01,  2.88528912e-02,  1.18043363e-01,\n",
      "          -3.11209597e-02, -1.35572091e-01, -1.74126044e-01,\n",
      "           4.53511141e-02,  1.56383857e-01]],\n",
      "\n",
      "        [[ 1.30491972e-01,  9.57849845e-02, -9.40489769e-02,\n",
      "          -1.35416705e-02, -1.69870630e-01,  2.10635364e-02,\n",
      "           1.34330869e-01, -1.17732994e-01, -9.78192464e-02,\n",
      "           5.69398031e-02, -1.09201297e-01, -3.44036371e-02,\n",
      "          -4.60557453e-03,  9.75209549e-02,  1.22662317e-02,\n",
      "          -9.44572762e-02,  1.65702458e-02,  4.76202853e-02,\n",
      "           1.72669813e-02,  1.10849075e-01,  1.69580787e-01,\n",
      "          -9.14497077e-02,  8.82447362e-02,  2.58109905e-02,\n",
      "           1.19489841e-01, -2.39073224e-02,  2.18086392e-02,\n",
      "          -1.03611335e-01, -9.24275890e-02, -1.64250731e-01,\n",
      "          -9.21303481e-02, -1.83259770e-01]],\n",
      "\n",
      "        [[ 1.30006433e-01, -1.44018427e-01, -4.19192500e-02,\n",
      "           1.32937178e-01, -2.11439878e-02, -8.03468823e-02,\n",
      "          -9.87018109e-04, -7.75700361e-02, -1.74253923e-03,\n",
      "           2.66317441e-03, -1.04946174e-01, -1.45571699e-04,\n",
      "          -5.58167100e-02,  1.35202006e-01, -1.42504320e-01,\n",
      "          -2.75169183e-02,  4.64208089e-02, -7.35960016e-03,\n",
      "           1.04503751e-01,  5.64815067e-02,  5.14141023e-02,\n",
      "           5.84472679e-02,  8.60061124e-02, -1.47512168e-01,\n",
      "          -1.75518632e-01,  1.14893198e-01,  2.57911882e-03,\n",
      "           5.49459644e-02, -1.06819637e-01, -1.22419737e-01,\n",
      "          -1.02746412e-01,  1.03907503e-01]]]], dtype=float32)>\n",
      "<tf.Variable 'W0:0' shape=(3, 3, 1, 32) dtype=float32, numpy=\n",
      "array([[[[ 1.79112658e-01,  3.73459570e-02, -1.67107731e-02,\n",
      "           2.67349351e-02, -9.69983339e-02,  5.47100306e-02,\n",
      "          -3.81687693e-02,  1.24128602e-01,  1.23022407e-01,\n",
      "          -5.85945509e-02, -3.19609679e-02,  2.55173407e-02,\n",
      "          -7.69047141e-02, -2.19351705e-02,  3.11940201e-02,\n",
      "           7.64513612e-02, -4.69256900e-02, -1.97769701e-02,\n",
      "          -3.16374563e-02, -1.39500340e-02,  1.02816131e-02,\n",
      "          -1.17815033e-01, -2.53448095e-02,  8.85214135e-02,\n",
      "           2.03830823e-02, -4.27313894e-02, -4.56542056e-03,\n",
      "          -1.30703390e-01,  3.70277613e-02, -4.73631062e-02,\n",
      "           2.45657731e-02,  2.29552537e-02]],\n",
      "\n",
      "        [[ 3.00004501e-02, -1.96336792e-03, -1.69537179e-02,\n",
      "          -7.25311190e-02,  1.08779438e-01,  4.02858108e-02,\n",
      "          -9.02936310e-02,  8.87157321e-02, -4.75768633e-02,\n",
      "          -9.41240937e-02,  2.74229143e-02,  2.58841515e-02,\n",
      "          -1.25610158e-01, -6.69573322e-02,  4.17324230e-02,\n",
      "          -1.63827747e-01, -1.20239303e-01, -1.34554356e-01,\n",
      "          -6.39163330e-02,  4.19057682e-02, -1.12995924e-02,\n",
      "           1.72060693e-03, -7.89894443e-03,  3.59597802e-02,\n",
      "           1.52184740e-02,  9.80427638e-02,  3.13384198e-02,\n",
      "           2.62483512e-03,  3.50989029e-02,  6.04678467e-02,\n",
      "          -6.61500320e-02,  4.95259240e-02]],\n",
      "\n",
      "        [[ 4.59399354e-03, -1.39174193e-01,  1.35343477e-01,\n",
      "           8.82808194e-02,  7.25796353e-03,  5.69838844e-02,\n",
      "           1.05550364e-01,  1.94634907e-02, -9.00703147e-02,\n",
      "           1.28388286e-01,  1.26834899e-01,  1.05911419e-01,\n",
      "           1.26646474e-01,  4.88352925e-02,  6.88950485e-03,\n",
      "          -1.31087586e-01,  2.67701969e-02, -1.82354636e-03,\n",
      "          -7.80728832e-02, -1.48503318e-01,  1.33100906e-02,\n",
      "          -1.80433795e-01, -4.09730226e-02, -8.43551829e-02,\n",
      "           1.17010847e-01,  7.83636607e-03, -2.93856189e-02,\n",
      "          -4.75181602e-02, -6.28818059e-03,  7.18935877e-02,\n",
      "          -5.56080863e-02,  7.26742223e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 8.07268098e-02, -5.39560094e-02,  8.57834220e-02,\n",
      "           4.11088504e-02, -4.92063947e-02,  9.20955539e-02,\n",
      "           1.39205918e-01, -8.60517472e-02,  7.34852552e-02,\n",
      "           4.36083823e-02,  1.12987429e-01,  6.28276691e-02,\n",
      "           1.09013133e-01, -4.04722281e-02, -9.99328941e-02,\n",
      "           2.20804084e-02,  3.11732441e-02, -4.90632281e-02,\n",
      "          -9.48116779e-02,  3.52269411e-02, -1.76149476e-02,\n",
      "          -3.14051360e-02, -9.80106369e-03, -1.50045578e-03,\n",
      "          -3.00252661e-02, -1.07816227e-01, -2.69017741e-02,\n",
      "          -2.03992780e-02, -5.54176904e-02, -4.26877663e-02,\n",
      "           3.98572236e-02,  8.92336741e-02]],\n",
      "\n",
      "        [[-8.88559595e-02, -7.72069842e-02, -3.69868912e-02,\n",
      "           1.18169216e-02, -1.58387590e-02,  1.62418559e-03,\n",
      "           1.23455033e-01, -1.73318572e-02, -2.54464019e-02,\n",
      "          -8.51601511e-02, -6.32438883e-02,  1.27035037e-01,\n",
      "          -3.81929008e-03, -6.58022016e-02,  1.81884512e-01,\n",
      "          -1.21835947e-01, -5.50227463e-02,  1.15299840e-02,\n",
      "           1.30192101e-01,  4.23724344e-03,  1.09185956e-01,\n",
      "           4.03511524e-02,  7.28820544e-03,  6.43133223e-02,\n",
      "          -1.21923447e-01,  4.35483381e-02, -3.00792349e-03,\n",
      "          -6.26349971e-02, -1.05160378e-01, -9.19682980e-02,\n",
      "          -4.92697284e-02, -1.55746162e-01]],\n",
      "\n",
      "        [[ 2.97656301e-02, -1.28818294e-02,  1.20787613e-01,\n",
      "           1.82169020e-01,  1.12416089e-01, -8.18874463e-02,\n",
      "          -6.52500540e-02,  9.62243378e-02,  5.13674952e-02,\n",
      "           9.62664373e-03, -1.47878109e-02,  3.60717326e-02,\n",
      "          -1.34591535e-01, -1.61269739e-01, -2.82326639e-02,\n",
      "          -4.53755409e-02,  1.53173193e-01,  6.15546517e-02,\n",
      "           3.31117287e-02, -1.16755605e-01,  4.48470116e-02,\n",
      "           3.95699702e-02, -1.13270499e-01, -5.80976196e-02,\n",
      "          -6.92795366e-02,  1.52029959e-03, -1.03613332e-01,\n",
      "           1.02486104e-01, -5.64630218e-02, -1.08132549e-01,\n",
      "          -6.44334927e-02, -2.19416749e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 2.73256861e-02,  1.02594998e-02,  1.49401307e-01,\n",
      "           4.48071770e-02, -1.48808062e-02, -7.45736703e-04,\n",
      "           1.78049862e-01,  5.51180867e-03, -9.38974917e-02,\n",
      "          -1.00008629e-01,  2.53571402e-02, -7.91181922e-02,\n",
      "          -7.99918100e-02, -5.68291321e-02,  1.39992228e-02,\n",
      "           9.81273949e-02, -4.26722392e-02, -1.83159467e-02,\n",
      "           1.02918029e-01, -1.67413145e-01,  4.98657450e-02,\n",
      "          -2.42879633e-02,  7.90439025e-02,  4.99230810e-02,\n",
      "           1.15848742e-01,  2.88874004e-02,  1.18026778e-01,\n",
      "          -3.11224516e-02, -1.35571733e-01, -1.74126074e-01,\n",
      "           4.53618243e-02,  1.56397149e-01]],\n",
      "\n",
      "        [[ 1.30450785e-01,  9.57676470e-02, -9.40614492e-02,\n",
      "          -1.35309501e-02, -1.69868901e-01,  2.10775882e-02,\n",
      "           1.34372294e-01, -1.17752962e-01, -9.78172123e-02,\n",
      "           5.69333620e-02, -1.09214433e-01, -3.44178937e-02,\n",
      "          -4.60497616e-03,  9.75259393e-02,  1.22635337e-02,\n",
      "          -9.44597572e-02,  1.66063085e-02,  4.76066060e-02,\n",
      "           1.72446724e-02,  1.10862717e-01,  1.69614583e-01,\n",
      "          -9.14492831e-02,  8.82735923e-02,  2.58112140e-02,\n",
      "           1.19501241e-01, -2.38792878e-02,  2.17857398e-02,\n",
      "          -1.03618741e-01, -9.24273133e-02, -1.64250791e-01,\n",
      "          -9.21307206e-02, -1.83226332e-01]],\n",
      "\n",
      "        [[ 1.29977643e-01, -1.44019395e-01, -4.19319123e-02,\n",
      "           1.32977992e-01, -2.11302228e-02, -8.03258792e-02,\n",
      "          -9.66361025e-04, -7.75718540e-02, -1.73264870e-03,\n",
      "           2.66662962e-03, -1.04963534e-01, -1.68900980e-04,\n",
      "          -5.58168963e-02,  1.35202274e-01, -1.42519206e-01,\n",
      "          -2.75181290e-02,  4.64738421e-02, -7.37244822e-03,\n",
      "           1.04478233e-01,  5.64825796e-02,  5.14413938e-02,\n",
      "           5.84439263e-02,  8.60047787e-02, -1.47511244e-01,\n",
      "          -1.75517112e-01,  1.14913590e-01,  2.54684617e-03,\n",
      "           5.49281128e-02, -1.06819339e-01, -1.22419789e-01,\n",
      "          -1.02747068e-01,  1.03949778e-01]]]], dtype=float32)>\n",
      ".A. shape 1: (120, 28, 28, 1)\n",
      "Z. tf.nn.conv2d shape 1: (120, 28, 28, 32)\n",
      "A. tf.nn.conv2d shape 1: (120, 28, 28, 32)\n",
      "A. tf.Max shape 1: (120, 14, 14, 32)\n",
      "A. shape 2: (120, 14, 14, 32)\n",
      "Z. tf.nn.conv2d shape 2: (120, 14, 14, 64)\n",
      "A. tf.nn.conv2d shape 2: (120, 14, 14, 64)\n",
      "A. tf.Max shape 2: (120, 7, 7, 64)\n",
      "A shape before flat: (120, 7, 7, 64)\n",
      "F shape: (120, 3136)\n",
      "tf.transpose(self.last_dense): (10, 120)\n",
      "self.last_dense: (120, 10)\n",
      "tf.reduce_mean(loss): 2.322880506515503\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\github_\\ComputerVision\\Assignment_4\\Model1.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 266>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=259'>260</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSteps per epoch\u001b[39m\u001b[39m'\u001b[39m, steps_per_epoch)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=263'>264</a>\u001b[0m tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mrun_functions_eagerly(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=265'>266</a>\u001b[0m history \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mtrain(\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=266'>267</a>\u001b[0m     x_train,y_train,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=267'>268</a>\u001b[0m     x_test, y_test,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=268'>269</a>\u001b[0m     epochs, steps_per_epoch,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=269'>270</a>\u001b[0m     batch_size)\n",
      "\u001b[1;32md:\\github_\\ComputerVision\\Assignment_4\\Model1.ipynb Cell 4'\u001b[0m in \u001b[0;36mCNN.train\u001b[1;34m(self, x_train, y_train, x_test, y_test, epochs, steps_per_epoch, batch_size)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=173'>174</a>\u001b[0m x_batch \u001b[39m=\u001b[39m x_train[i\u001b[39m*\u001b[39mbatch_size:(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mbatch_size]\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=174'>175</a>\u001b[0m y_batch \u001b[39m=\u001b[39m y_train[i\u001b[39m*\u001b[39mbatch_size:(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mbatch_size]\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=176'>177</a>\u001b[0m batch_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainOnBatch(x_batch, y_batch)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=177'>178</a>\u001b[0m epoch_train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_loss\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=179'>180</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m%\u001b[39m\u001b[39mint\u001b[39m(steps_per_epoch\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32md:\\github_\\ComputerVision\\Assignment_4\\Model1.ipynb Cell 4'\u001b[0m in \u001b[0;36mCNN.trainOnBatch\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=209'>210</a>\u001b[0m \u001b[39m#X = self.dropout(X)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=210'>211</a>\u001b[0m Z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforwardpass(X)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=212'>213</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcomputeLoss(Y, Z)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=213'>214</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mComputed Loss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=214'>215</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdw[i] \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mWeights[i])\n",
      "\u001b[1;32md:\\github_\\ComputerVision\\Assignment_4\\Model1.ipynb Cell 4'\u001b[0m in \u001b[0;36mCNN.computeLoss\u001b[1;34m(self, Y, Z)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=155'>156</a>\u001b[0m     \u001b[39minput\u001b[39m()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=156'>157</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtf.reduce_mean(loss): \u001b[39m\u001b[39m{\u001b[39;00mtf\u001b[39m.\u001b[39mreduce_mean(loss)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=157'>158</a>\u001b[0m \u001b[39minput\u001b[39;49m()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=158'>159</a>\u001b[0m \u001b[39mreturn\u001b[39;00m (tf\u001b[39m.\u001b[39mreduce_mean(loss))\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py:1076\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/ipykernel/kernelbase.py?line=1071'>1072</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_allow_stdin:\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/ipykernel/kernelbase.py?line=1072'>1073</a>\u001b[0m     \u001b[39mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/ipykernel/kernelbase.py?line=1073'>1074</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/ipykernel/kernelbase.py?line=1074'>1075</a>\u001b[0m     )\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/ipykernel/kernelbase.py?line=1075'>1076</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_request(\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/ipykernel/kernelbase.py?line=1076'>1077</a>\u001b[0m     \u001b[39mstr\u001b[39;49m(prompt),\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/ipykernel/kernelbase.py?line=1077'>1078</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent_ident[\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/ipykernel/kernelbase.py?line=1078'>1079</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_parent(\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/ipykernel/kernelbase.py?line=1079'>1080</a>\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/ipykernel/kernelbase.py?line=1080'>1081</a>\u001b[0m )\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py:1121\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/ipykernel/kernelbase.py?line=1117'>1118</a>\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/ipykernel/kernelbase.py?line=1118'>1119</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/ipykernel/kernelbase.py?line=1119'>1120</a>\u001b[0m     \u001b[39m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/ipykernel/kernelbase.py?line=1120'>1121</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInterrupted by user\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/ipykernel/kernelbase.py?line=1121'>1122</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/ipykernel/kernelbase.py?line=1122'>1123</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mInvalid Message:\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def printIMG(x,y, idx):\n",
    "    label_dict = {\n",
    " 0: 'T-shirt/top',\n",
    " 1: 'Trouser',\n",
    " 2: 'Pullover',\n",
    " 3: 'Dress',\n",
    " 4: 'Coat',\n",
    " 5: 'Sandal',\n",
    " 6: 'Shirt',\n",
    " 7: 'Sneaker',\n",
    " 8: 'Bag',\n",
    " 9: 'Ankle boot',\n",
    "}\n",
    "\n",
    "    plt.imshow(x[idx])\n",
    "    plt.xlabel(label_dict[idx])\n",
    "# plt.imshow(x[0])\n",
    "\n",
    "def preprocessing():\n",
    "    (x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data() #tf.keras.datasets.mnist.load_data(path=\"mnist.npz\") # \n",
    "    x_train =x_train/255  \n",
    "    x_test = x_test/255 \n",
    "\n",
    "    # Make categorical for loss\n",
    "    y_train = tf.keras.utils.to_categorical(y_train)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "    # reshape for 3 dim\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "    x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "    \n",
    "    return (x_train, y_train, x_test, y_test)\n",
    "\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self, num_input, layers ,lastDense, lr, dropout, debug=False):\n",
    "        self.hiddenlayers =layers\n",
    "        self.num_features = layers[0]\n",
    "        self.num_classes = layers[-1]\n",
    "        self.L =  len(layers) #len(self.Weights)+1  # len(layers)\n",
    "\n",
    "        self.debug = debug\n",
    "\n",
    "        self.lr = lr\n",
    "        self.drouput = dropout\n",
    "\n",
    "        # paramerters\n",
    "        self.Weights = {}\n",
    "        self.biases = {}\n",
    "        self.dw = {}\n",
    "        self.db = {}\n",
    "\n",
    "        self.last_dense = lastDense\n",
    "        # should happen at the beginning when initlizing the \n",
    "        self.initilizeWeight()\n",
    "\n",
    "    def initilizeWeight(self):\n",
    "        # print(\"initilizeWeight\")\n",
    "        for i in range(1, self.L-1):\n",
    "            \n",
    "            self.Weights[i] =  self.hiddenlayers[i]#tf.Variable(tf.random.normal(shape =(self.hiddenlayers[i], self.hiddenlayers[i-1]))) #, initializer =  tf.contrib.layers.xavier_initializer(seed = 0)))\n",
    "            if self.debug: print(f\"self.Weights[i].shape: {self.Weights[i]} \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def compute_loss(self, A, Y):\n",
    "        # print(\"compute_loss\")\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(Y,A)\n",
    "        # Mean over multiple dim\n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "    def forwardpass(self, X):\n",
    "        # print(\"forwardpass\")\n",
    "\n",
    "\n",
    "        if self.debug: print(f\"self.Weights: {len(self.Weights)}\")\n",
    "\n",
    "        \n",
    "        A = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        for i in range(1, len(self.Weights)+1):\n",
    "\n",
    "            if self.debug: \n",
    "                print(f\" {i} {self.Weights[i].shape} \")  \n",
    "                input()\n",
    "            \n",
    "            print(f\"A. shape {i}: {A.shape}\")\n",
    "            Z = tf.nn.conv2d(A, self.Weights[i], strides = [1,1,1,1], padding = 'SAME')\n",
    "            print(f\"Z. tf.nn.conv2d shape {i}: {Z.shape}\")\n",
    "\n",
    "            A = tf.nn.relu(Z)\n",
    "            print(f\"A. tf.nn.conv2d shape {i}: {A.shape}\")\n",
    "\n",
    "            A = tf.nn.max_pool(A, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "            print(f\"A. tf.Max shape {i}: {A.shape}\")\n",
    "\n",
    "            if self.debug: \n",
    "                input()\n",
    "\n",
    "        print(f\"A shape before flat: {A.shape}\")\n",
    "        F = tf.compat.v1.layers.flatten(A)\n",
    "        Z3 = tf.compat.v1.layers.dense(F, self.num_classes, activation=None)   #, activation_fn=None\n",
    "        #Z3= tf.keras.layers.Dense(F, self.num_classes, activation=None)\n",
    "        print(f\"F shape: {F.shape}\")\n",
    "        print(f\"tf.transpose(self.last_dense): {tf.transpose(self.last_dense).shape}\")                \n",
    "        print(f\"self.last_dense: {self.last_dense.shape}\")\n",
    "\n",
    "        input()\n",
    "\n",
    "        # Z3 = tf.matmul(tf.transpose(F),self.last_dense) \n",
    "        # if self.debug: input()\n",
    "\n",
    "        A = Z3    \n",
    "        return A\n",
    "\n",
    "\n",
    "    def updateParams(self):\n",
    "        \"\"\" \n",
    "        We have all the weights and biases. now we need to update the weights with gd\n",
    "        The formula is \n",
    "        \"\"\"\n",
    "        # print(\"updateParams\")\n",
    "\n",
    "        # check also with assignning sub\n",
    "        for i in range(1, len(self.Weights)):\n",
    "            input()\n",
    "            print(self.Weights[i])\n",
    "            self.Weights[i].assign_sub(self.lr * self.dw[i])\n",
    "            print(self.Weights[i])\n",
    "            #self.biases[i].assign_sub(self.lr * self.db[i]) \n",
    "\n",
    "\n",
    "    def printInfoModel(self):\n",
    "        print(f\"Number of features: {self.num_features}\")\n",
    "        print(f\"Number of classes: {self.num_classes}\")\n",
    "        print(f\"Number of self.Weights {len(self.Weights)}\")\n",
    "\n",
    "\n",
    "        for i in range(1, len(self.hiddenlayers)-1):\n",
    "            print(f\"Hidden Layer {i}: {self.hiddenlayers[i].shape}\")\n",
    "\n",
    "\n",
    "    def computeLoss(self, Y, Z):\n",
    "        # print(\"compute_loss\")\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(Y, Z) # try to use softmax\n",
    "        if self.debug: \n",
    "            print(f\"tf.reduce_mean(loss): {tf.reduce_mean(loss)}\")\n",
    "            input()\n",
    "        print(f\"tf.reduce_mean(loss): {tf.reduce_mean(loss)}\")\n",
    "        input()\n",
    "        return (tf.reduce_mean(loss))\n",
    "\n",
    "\n",
    "    def train(self, x_train, y_train, x_test, y_test, epochs, steps_per_epoch, batch_size):\n",
    "\n",
    "        history = {\n",
    "            'val_loss':[],\n",
    "            'train_loss':[],\n",
    "            'val_acc':[]\n",
    "        }\n",
    "        \n",
    "        for e in range(0, epochs):\n",
    "            epoch_train_loss = 0.\n",
    "            print('Epoch{}'.format(e), end='.')\n",
    "            for i in range(0, steps_per_epoch):\n",
    "                x_batch = x_train[i*batch_size:(i+1)*batch_size]\n",
    "                y_batch = y_train[i*batch_size:(i+1)*batch_size]\n",
    "                \n",
    "                batch_loss = self.trainOnBatch(x_batch, y_batch)\n",
    "                epoch_train_loss += batch_loss\n",
    "                \n",
    "                if i%int(steps_per_epoch/10) == 0:\n",
    "                    print(end='.')\n",
    "                    \n",
    "            history['train_loss'].append(epoch_train_loss/steps_per_epoch)\n",
    "            val_A = self.forwardpass(x_test)\n",
    "\n",
    "            val_loss = self.compute_loss(val_A, y_test).numpy()\n",
    "            history['val_loss'].append(val_loss)\n",
    "            val_preds = self.predict(x_test)\n",
    "            val_acc =    np.mean(np.argmax(y_test, axis=1) == val_preds.numpy())\n",
    "            history['val_acc'].append(val_acc)\n",
    "            print('Val acc:',val_acc)\n",
    "        return history\n",
    "\n",
    "    def dropout(self, X):\n",
    "        a = tf.random.uniform((X.shape[0], X.shape[1]), dtype=tf.dtypes.float32)\n",
    "        b = tf.where(a<self.drouput , 0,1)\n",
    "        b = tf.cast(b, tf.dtypes.float32)\n",
    "        return (tf.math.multiply(b,X))\n",
    "\n",
    "\n",
    "    def trainOnBatch(self, X, Y):\n",
    "\n",
    "        X = tf.convert_to_tensor(X, dtype = tf.float32)\n",
    "        Y = tf.convert_to_tensor(Y,dtype = tf.float32)\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            for i in range(1, len(self.Weights)):\n",
    "                if self.debug: print(f\"tape: {i}\")\n",
    "\n",
    "                #X = self.dropout(X)\n",
    "                Z = self.forwardpass(X)\n",
    "                \n",
    "                loss = self.computeLoss(Y, Z)\n",
    "                print(\"Computed Loss\")\n",
    "                self.dw[i] = tape.gradient(loss, self.Weights[i])\n",
    "                print(f\"self.dw[i]: {self.dw[i].shape}\")\n",
    "\n",
    "                if self.debug:\n",
    "                    print(f\"type(loss): {type(loss)}\")\n",
    "                    print(f\"type(Weights[i]): {type(self.Weights[i])}\")\n",
    "                    print(f\"type(self.dw[i]): {type(self.dw[i])}\")\n",
    "\n",
    "                #self.db[i] = tape.gradient(loss, self.biases[i])\n",
    "        del tape\n",
    "        self.updateParams()\n",
    "        return loss#numpy()\n",
    "\n",
    "    def predict(self, X):\n",
    "        A = self.forwardpass(X)\n",
    "        return tf.argmax(tf.nn.softmax(A), axis=1)\n",
    "        \n",
    "\n",
    "\n",
    "n_classes = 10\n",
    "n_Input = 784\n",
    "weights = [\n",
    "    n_Input,\n",
    "    tf.compat.v1.get_variable('W0', shape=(3,3,1,32), initializer=tf.keras.initializers.glorot_normal()),\n",
    "     tf.compat.v1.get_variable('W1', shape=(3,3,32,64), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    #  tf.compat.v1.get_variable('W2', shape=(3,3,64,128), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    #  tf.compat.v1.get_variable('W3', shape=(4*4*128,128), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    #  tf.compat.v1.get_variable('W6', shape=(64,n_classes), initializer=tf.keras.initializers.glorot_normal()),\n",
    "     n_classes,\n",
    "]\n",
    "\n",
    "last = tf.compat.v1.get_variable('W6', shape=(120,n_classes), initializer=tf.keras.initializers.glorot_normal())\n",
    "\n",
    "\n",
    "net = CNN(n_Input,weights,last, 3e-3, 0.3, debug = False)\n",
    "net.printInfoModel()\n",
    "\n",
    "\n",
    "\n",
    "(x_train, y_train, x_test, y_test) = preprocessing()\n",
    "\n",
    "batch_size = 120\n",
    "epochs = 25\n",
    "steps_per_epoch = int(x_train.shape[0]/batch_size)\n",
    "lr = 3e-3\n",
    "print('Steps per epoch', steps_per_epoch)\n",
    "\n",
    "\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "history = net.train(\n",
    "    x_train,y_train,\n",
    "    x_test, y_test,\n",
    "    epochs, steps_per_epoch,\n",
    "    batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_Input = 784\n",
    "weights = [\n",
    "    n_Input,\n",
    "    tf.compat.v1.get_variable('W0', shape=(3,3,1,32), initializer=tf.keras.initializers.glorot_normal()),\n",
    "     tf.compat.v1.get_variable('W1', shape=(3,3,32,64), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    #  tf.compat.v1.get_variable('W2', shape=(3,3,64,128), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    #  tf.compat.v1.get_variable('W3', shape=(4*4*128,128), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    #  tf.compat.v1.get_variable('W6', shape=(64,n_classes), initializer=tf.keras.initializers.glorot_normal()),\n",
    "     n_classes,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 784\n",
      "Number of classes: 10\n",
      "Number of self.Weights 2\n",
      "Hidden Layer 1: (3, 3, 1, 32)\n",
      "Hidden Layer 2: (3, 3, 32, 64)\n"
     ]
    }
   ],
   "source": [
    "net = CNN(n_Input,weights,3e-3, 0.3, debug = False)\n",
    "net.printInfoModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch 500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(x_train, y_train, x_test, y_test) = preprocessing()\n",
    "\n",
    "batch_size = 120\n",
    "epochs = 25\n",
    "steps_per_epoch = int(x_train.shape[0]/batch_size)\n",
    "lr = 3e-3\n",
    "print('Steps per epoch', steps_per_epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0.WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18404\\676040336.py:104: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  F = tf.compat.v1.layers.flatten(A)\n",
      "D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:541: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18404\\676040336.py:112: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  Z3 = tf.compat.v1.layers.dense(F, self.num_classes, activation=None)   #, activation_fn=None\n",
      "D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........Val acc: 0.0843\n",
      "Epoch1...........Val acc: 0.2469\n",
      "Epoch2...........Val acc: 0.0503\n",
      "Epoch3...........Val acc: 0.088\n",
      "Epoch4...........Val acc: 0.0613\n",
      "Epoch5...........Val acc: 0.0783\n",
      "Epoch6...........Val acc: 0.1037\n",
      "Epoch7...........Val acc: 0.147\n",
      "Epoch8...........Val acc: 0.0524\n",
      "Epoch9...........Val acc: 0.1483\n",
      "Epoch10...........Val acc: 0.0792\n",
      "Epoch11...........Val acc: 0.0527\n",
      "Epoch12...........Val acc: 0.0948\n",
      "Epoch13...........Val acc: 0.1173\n",
      "Epoch14...........Val acc: 0.0555\n",
      "Epoch15...."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\github_\\ComputerVision\\Assignment_4\\Model1.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000005?line=0'>1</a>\u001b[0m tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mrun_functions_eagerly(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000005?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mtrain(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000005?line=2'>3</a>\u001b[0m     x_train,y_train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000005?line=3'>4</a>\u001b[0m     x_test, y_test,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000005?line=4'>5</a>\u001b[0m     epochs, steps_per_epoch,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000005?line=5'>6</a>\u001b[0m     batch_size)\n",
      "\u001b[1;32md:\\github_\\ComputerVision\\Assignment_4\\Model1.ipynb Cell 3'\u001b[0m in \u001b[0;36mCNN.train\u001b[1;34m(self, x_train, y_train, x_test, y_test, epochs, steps_per_epoch, batch_size)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=163'>164</a>\u001b[0m x_batch \u001b[39m=\u001b[39m x_train[i\u001b[39m*\u001b[39mbatch_size:(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mbatch_size]\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=164'>165</a>\u001b[0m y_batch \u001b[39m=\u001b[39m y_train[i\u001b[39m*\u001b[39mbatch_size:(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mbatch_size]\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=166'>167</a>\u001b[0m batch_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainOnBatch(x_batch, y_batch)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=167'>168</a>\u001b[0m epoch_train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_loss\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=169'>170</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m%\u001b[39m\u001b[39mint\u001b[39m(steps_per_epoch\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32md:\\github_\\ComputerVision\\Assignment_4\\Model1.ipynb Cell 3'\u001b[0m in \u001b[0;36mCNN.trainOnBatch\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=198'>199</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug: \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtape: \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=200'>201</a>\u001b[0m \u001b[39m#X = self.dropout(X)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=201'>202</a>\u001b[0m Z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforwardpass(X)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=203'>204</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomputeLoss(Y, Z)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=204'>205</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdw[i] \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mWeights[i])\n",
      "\u001b[1;32md:\\github_\\ComputerVision\\Assignment_4\\Model1.ipynb Cell 3'\u001b[0m in \u001b[0;36mCNN.forwardpass\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=103'>104</a>\u001b[0m F \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mflatten(A)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=104'>105</a>\u001b[0m \u001b[39m# f = tf.keras.Fl\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=105'>106</a>\u001b[0m \u001b[39m# print(\"After f\")\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=106'>107</a>\u001b[0m \n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=107'>108</a>\u001b[0m \u001b[39m# FULLY-CONNECTED without non-linear activation function (not not call softmax).\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=108'>109</a>\u001b[0m \u001b[39m# 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=109'>110</a>\u001b[0m \u001b[39m# print(\"Before Z3\")\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=111'>112</a>\u001b[0m Z3 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mdense(F, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_classes, activation\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)   \u001b[39m#, activation_fn=None\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=113'>114</a>\u001b[0m \u001b[39m# print(\"Before Z3\")\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=114'>115</a>\u001b[0m \n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=115'>116</a>\u001b[0m \u001b[39m# print(f\"Z3: {Z3.shape}\")\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=116'>117</a>\u001b[0m \n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=117'>118</a>\u001b[0m \u001b[39m# input()\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000002?line=118'>119</a>\u001b[0m A \u001b[39m=\u001b[39m Z3    \n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:261\u001b[0m, in \u001b[0;36mdense\u001b[1;34m(inputs, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/core.py?line=241'>242</a>\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/core.py?line=242'>243</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m`tf.layers.dense` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/core.py?line=243'>244</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/core.py?line=244'>245</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPlease use `tf.keras.layers.Dense` instead.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/core.py?line=245'>246</a>\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/core.py?line=246'>247</a>\u001b[0m layer \u001b[39m=\u001b[39m Dense(units,\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/core.py?line=247'>248</a>\u001b[0m               activation\u001b[39m=\u001b[39mactivation,\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/core.py?line=248'>249</a>\u001b[0m               use_bias\u001b[39m=\u001b[39muse_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/core.py?line=258'>259</a>\u001b[0m               _scope\u001b[39m=\u001b[39mname,\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/core.py?line=259'>260</a>\u001b[0m               _reuse\u001b[39m=\u001b[39mreuse)\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/core.py?line=260'>261</a>\u001b[0m \u001b[39mreturn\u001b[39;00m layer\u001b[39m.\u001b[39;49mapply(inputs)\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\keras\\engine\\base_layer.py:2296\u001b[0m, in \u001b[0;36mLayer.apply\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=2278'>2279</a>\u001b[0m \u001b[39m\"\"\"Deprecated, do NOT use!\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=2279'>2280</a>\u001b[0m \n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=2280'>2281</a>\u001b[0m \u001b[39mThis is an alias of `self.__call__`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=2288'>2289</a>\u001b[0m \u001b[39m  Output tensor(s).\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=2289'>2290</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=2290'>2291</a>\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=2291'>2292</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m`layer.apply` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=2292'>2293</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=2293'>2294</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPlease use `layer.__call__` method instead.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=2294'>2295</a>\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=2295'>2296</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\keras\\legacy_tf_layers\\base.py:569\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/base.py?line=565'>566</a>\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mscope\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m scope\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/base.py?line=567'>568</a>\u001b[0m   \u001b[39m# Actually call layer\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/base.py?line=568'>569</a>\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Layer, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/base.py?line=570'>571</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/base.py?line=571'>572</a>\u001b[0m   \u001b[39m# Update global default collections.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/legacy_tf_layers/base.py?line=572'>573</a>\u001b[0m   _add_elements_to_collection(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdates, tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mGraphKeys\u001b[39m.\u001b[39mUPDATE_OPS)\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\keras\\engine\\base_layer.py:1096\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=1091'>1092</a>\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=1093'>1094</a>\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=1094'>1095</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=1095'>1096</a>\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=1097'>1098</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/engine/base_layer.py?line=1098'>1099</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/utils/traceback_utils.py?line=89'>90</a>\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/utils/traceback_utils.py?line=90'>91</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/utils/traceback_utils.py?line=91'>92</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/utils/traceback_utils.py?line=92'>93</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/utils/traceback_utils.py?line=93'>94</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/utils/traceback_utils.py?line=94'>95</a>\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\keras\\layers\\core\\dense.py:219\u001b[0m, in \u001b[0;36mDense.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/layers/core/dense.py?line=215'>216</a>\u001b[0m     outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39membedding_lookup_sparse(\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/layers/core/dense.py?line=216'>217</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel, ids, weights, combiner\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/layers/core/dense.py?line=217'>218</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/layers/core/dense.py?line=218'>219</a>\u001b[0m     outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mmatmul(a\u001b[39m=\u001b[39;49minputs, b\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel)\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/layers/core/dense.py?line=219'>220</a>\u001b[0m \u001b[39m# Broadcast kernel to inputs.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/layers/core/dense.py?line=220'>221</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/keras/layers/core/dense.py?line=221'>222</a>\u001b[0m   outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mtensordot(inputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel, [[rank \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m], [\u001b[39m0\u001b[39m]])\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/util/dispatch.py?line=1079'>1080</a>\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/util/dispatch.py?line=1080'>1081</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/util/dispatch.py?line=1081'>1082</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/util/dispatch.py?line=1082'>1083</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/util/dispatch.py?line=1083'>1084</a>\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/util/dispatch.py?line=1084'>1085</a>\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/util/dispatch.py?line=1085'>1086</a>\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3713\u001b[0m, in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/ops/math_ops.py?line=3709'>3710</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39mbatch_mat_mul_v3(\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/ops/math_ops.py?line=3710'>3711</a>\u001b[0m       a, b, adj_x\u001b[39m=\u001b[39madjoint_a, adj_y\u001b[39m=\u001b[39madjoint_b, Tout\u001b[39m=\u001b[39moutput_type, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/ops/math_ops.py?line=3711'>3712</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/ops/math_ops.py?line=3712'>3713</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49mmat_mul(\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/ops/math_ops.py?line=3713'>3714</a>\u001b[0m       a, b, transpose_a\u001b[39m=\u001b[39;49mtranspose_a, transpose_b\u001b[39m=\u001b[39;49mtranspose_b, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6012\u001b[0m, in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/ops/gen_math_ops.py?line=6009'>6010</a>\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/ops/gen_math_ops.py?line=6010'>6011</a>\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/ops/gen_math_ops.py?line=6011'>6012</a>\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/ops/gen_math_ops.py?line=6012'>6013</a>\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMatMul\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, a, b, \u001b[39m\"\u001b[39;49m\u001b[39mtranspose_a\u001b[39;49m\u001b[39m\"\u001b[39;49m, transpose_a, \u001b[39m\"\u001b[39;49m\u001b[39mtranspose_b\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/ops/gen_math_ops.py?line=6013'>6014</a>\u001b[0m       transpose_b)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/ops/gen_math_ops.py?line=6014'>6015</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/ops/gen_math_ops.py?line=6015'>6016</a>\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "history = net.train(\n",
    "    x_train,y_train,\n",
    "    x_test, y_test,\n",
    "    epochs, steps_per_epoch,\n",
    "    batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imp 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating placeholders\n",
    "a = tf1.placeholder(tf.float32)\n",
    "b = tf1.placeholder(tf.float32)\n",
    "\n",
    "# Assigning addition operation w.r.t. a and b to node add\n",
    "add = a + b\n",
    "\n",
    "# Create session object\n",
    "sess = tf1.Session()\n",
    "\n",
    "# Executing add by passing the values [1, 3] [2, 4] for a and b respectively\n",
    "output = sess.run(add, {a: [1,3], b: [2, 4]})\n",
    "print('Adding a and b:', output)\n",
    "print('Datatype:', output.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train, x_test, y_test) = preprocessing()\n",
    "\n",
    "\n",
    "# MNIST data input (img shape: 28*28)\n",
    "n_input = 28\n",
    "\n",
    "# MNIST total classes (0-9 digits)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.compat.v1.placeholder(\"float\", [None, 28,28,1])\n",
    "y = tf.compat.v1.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf1\n",
    "tf1.disable_v2_behavior()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def printIMG(x,y, idx):\n",
    "    label_dict = {\n",
    " 0: 'T-shirt/top',\n",
    " 1: 'Trouser',\n",
    " 2: 'Pullover',\n",
    " 3: 'Dress',\n",
    " 4: 'Coat',\n",
    " 5: 'Sandal',\n",
    " 6: 'Shirt',\n",
    " 7: 'Sneaker',\n",
    " 8: 'Bag',\n",
    " 9: 'Ankle boot',\n",
    "}\n",
    "\n",
    "    plt.imshow(x[idx])\n",
    "    plt.xlabel(label_dict[idx])\n",
    "# plt.imshow(x[0])\n",
    "\n",
    "def preprocessing():\n",
    "    (x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data() #tf.keras.datasets.mnist.load_data(path=\"mnist.npz\") # \n",
    "    x_train =x_train/255  #np.reshape(x_train, (x_train.shape[0], 784))/255.\n",
    "    x_test = x_test/255 #np.reshape(x_test, (x_test.shape[0], 784))/255.\n",
    "    y_train = tf.keras.utils.to_categorical(y_train)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "    x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "    # x_train=  tf.cast( tf.expand_dims(x_train,-1), dtype= tf.float32, name=None) \n",
    "    # x_test=  tf.cast( tf.expand_dims(tf.expand_dims(x_test,-1),-1), dtype= tf.float32, name=None) \n",
    "\n",
    "    # x_train= tf.image.grayscale_to_rgb(x_train, name=None)\n",
    "    # x_test= tf.image.grayscale_to_rgb(x_test, name=None)\n",
    "\n",
    "    # print(x_train.shape)\n",
    "    # print(x_train.shape)\n",
    "    # output =[]\n",
    "    # for t in data:\n",
    "    #     if(len(t)>1):\n",
    "    #         for d in t:\n",
    "    #             d = d/d.max()\n",
    "    #             output.append(d.reshape(d.shape[0],-1))\n",
    "    #     else:\n",
    "    #         d = d/d.max()\n",
    "    #         output.append(output.append(d.reshape(d.shape[0],-1)))\n",
    "    \n",
    "    return (x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data input (img shape: 28*28)\n",
    "n_input = 28\n",
    "\n",
    "# MNIST total classes (0-9 digits)\n",
    "n_classes = 10\n",
    "\n",
    "weights = {\n",
    "    'wc1': tf.compat.v1.get_variable('W0', shape=(3,3,1,32), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    'wc2': tf.compat.v1.get_variable('W1', shape=(3,3,32,64), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    'wc3': tf.compat.v1.get_variable('W2', shape=(3,3,64,128), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    'wd1': tf.compat.v1.get_variable('W3', shape=(4*4*128,128), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    'out': tf.compat.v1.get_variable('W6', shape=(128,n_classes), initializer=tf.keras.initializers.glorot_normal()),\n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.compat.v1.get_variable('B0', shape=(32), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    'bc2': tf.compat.v1.get_variable('B1', shape=(64), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    'bc3': tf.compat.v1.get_variable('B2', shape=(128), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    'bd1': tf.compat.v1.get_variable('B3', shape=(128), initializer=tf.keras.initializers.glorot_normal()),\n",
    "    'out': tf.compat.v1.get_variable('B4', shape=(10), initializer=tf.keras.initializers.glorot_normal()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases):  \n",
    "\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, weights wc1 and bias bc1.\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 14*14 matrix.\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, weights wc2 and bias bc2.\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 7*7 matrix.\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 4*4.\n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and add a bias term.\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train, x_test, y_test) = preprocessing()\n",
    "x_train= tf.cast(x_train, dtype= tf.float32)\n",
    "x_test= tf.cast(x_test, dtype= tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = conv_net(x_train, weights, biases)\n",
    "\n",
    "cost = tf1.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_train))\n",
    "optimizer = tf1.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "#Here, you check whether the index of the maximum value of the predicted image is equal to the actual labeled image. And both will be a column vector.\n",
    "correct_prediction = tf1.equal(tf.argmax(pred, 1), tf.argmax(y_train, 1))\n",
    "\n",
    "#calculate accuracy across all the given images and average them out.\n",
    "accuracy = tf1.reduce_mean(tf1.cast(correct_prediction, tf1.float32))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf1.GPUOptions(allow_growth=True)\n",
    "session = tf1.InteractiveSession(config=tf1.ConfigProto(gpu_options=gpu_options))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf1.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf1.placeholder(\"float\", [None, 28,28,1])\n",
    "y = tf1.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'MaxPool2d_3' defined at (most recent call last):\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\runpy.py\", line 192, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\asyncio\\base_events.py\", line 563, in run_forever\n      self._run_once()\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\asyncio\\base_events.py\", line 1844, in _run_once\n      handle._run()\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2900, in _run_cell\n      return runner(coro)\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3301, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_21060\\3884002539.py\", line 1, in <cell line: 1>\n      pred = conv_net(x_train, weights, biases)\n    File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_21060\\3236224927.py\", line 6, in conv_net\n      conv1 = maxpool2d(conv1, k=2)\n    File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_21060\\1805355015.py\", line 8, in maxpool2d\n      return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')\nNode: 'MaxPool2d_3'\nOOM when allocating tensor with shape[60000,32,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node MaxPool2d_3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\nOriginal stack trace for 'MaxPool2d_3':\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\runpy.py\", line 192, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n    app.start()\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\asyncio\\base_events.py\", line 563, in run_forever\n    self._run_once()\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\asyncio\\base_events.py\", line 1844, in _run_once\n    handle._run()\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n    await self.process_one()\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n    await dispatch(*args)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n    await result\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n    reply_content = await reply_content\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n    result = self._run_cell(\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2900, in _run_cell\n    return runner(coro)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3301, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_21060\\3884002539.py\", line 1, in <cell line: 1>\n    pred = conv_net(x_train, weights, biases)\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_21060\\3236224927.py\", line 6, in conv_net\n    conv1 = maxpool2d(conv1, k=2)\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_21060\\1805355015.py\", line 8, in maxpool2d\n    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1082, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 4800, in max_pool_v2\n    return op(\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1082, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 5030, in max_pool2d\n    return gen_nn_ops.max_pool(\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 5386, in max_pool\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 740, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3776, in _create_op_internal\n    ret = Operation(\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2175, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1377\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1375'>1376</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1376'>1377</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1377'>1378</a>\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1360\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1358'>1359</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1359'>1360</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1360'>1361</a>\u001b[0m                                 target_list, run_metadata)\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1453\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1450'>1451</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1451'>1452</a>\u001b[0m                         run_metadata):\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1452'>1453</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1453'>1454</a>\u001b[0m                                           fetch_list, target_list,\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1454'>1455</a>\u001b[0m                                           run_metadata)\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[60000,32,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node MaxPool2d_3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32md:\\github_\\ComputerVision\\Assignment_4\\Model1.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000019?line=29'>30</a>\u001b[0m     \u001b[39m# Run optimization op (backprop).\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000019?line=30'>31</a>\u001b[0m         \u001b[39m# Calculate batch loss and accuracy\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000019?line=31'>32</a>\u001b[0m     \u001b[39minput\u001b[39m()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000019?line=32'>33</a>\u001b[0m     opt \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39;49mrun(optimizer, feed_dict\u001b[39m=\u001b[39;49m{x: batch_x\u001b[39m.\u001b[39;49meval(),y: batch_y})\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000019?line=33'>34</a>\u001b[0m     loss, acc \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39mrun([cost, accuracy], feed_dict\u001b[39m=\u001b[39m{x: batch_x\u001b[39m.\u001b[39meval(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000019?line=34'>35</a>\u001b[0m                                                       y: batch_y})\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000019?line=35'>36</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIter \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, Loss= \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \\\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000019?line=36'>37</a>\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(loss) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, Training Accuracy= \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \\\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github_/ComputerVision/Assignment_4/Model1.ipynb#ch0000019?line=37'>38</a>\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39m{:.5f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(acc))\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\client\\session.py:967\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=963'>964</a>\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=965'>966</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=966'>967</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=967'>968</a>\u001b[0m                      run_metadata_ptr)\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=968'>969</a>\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[0;32m    <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=969'>970</a>\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1190\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1186'>1187</a>\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1187'>1188</a>\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1188'>1189</a>\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1189'>1190</a>\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1190'>1191</a>\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1191'>1192</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1192'>1193</a>\u001b[0m   results \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1370\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1366'>1367</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1368'>1369</a>\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1369'>1370</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1370'>1371</a>\u001b[0m                        run_metadata)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1371'>1372</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1372'>1373</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32mD:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1396\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1390'>1391</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39monly supports NHWC tensor format\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m message:\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1391'>1392</a>\u001b[0m   message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1392'>1393</a>\u001b[0m               \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mby modifying the config for creating the session eg.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1393'>1394</a>\u001b[0m               \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39msession_config.graph_options.rewrite_options.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1394'>1395</a>\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mdisable_meta_optimizer = True\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda_2/envs/tf2.4/lib/site-packages/tensorflow/python/client/session.py?line=1395'>1396</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'MaxPool2d_3' defined at (most recent call last):\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\runpy.py\", line 192, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\asyncio\\base_events.py\", line 563, in run_forever\n      self._run_once()\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\asyncio\\base_events.py\", line 1844, in _run_once\n      handle._run()\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2900, in _run_cell\n      return runner(coro)\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3301, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_21060\\3884002539.py\", line 1, in <cell line: 1>\n      pred = conv_net(x_train, weights, biases)\n    File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_21060\\3236224927.py\", line 6, in conv_net\n      conv1 = maxpool2d(conv1, k=2)\n    File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_21060\\1805355015.py\", line 8, in maxpool2d\n      return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')\nNode: 'MaxPool2d_3'\nOOM when allocating tensor with shape[60000,32,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node MaxPool2d_3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\nOriginal stack trace for 'MaxPool2d_3':\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\runpy.py\", line 192, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n    app.start()\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\asyncio\\base_events.py\", line 563, in run_forever\n    self._run_once()\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\asyncio\\base_events.py\", line 1844, in _run_once\n    handle._run()\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n    await self.process_one()\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n    await dispatch(*args)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n    await result\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n    reply_content = await reply_content\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n    result = self._run_cell(\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2900, in _run_cell\n    return runner(coro)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3301, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_21060\\3884002539.py\", line 1, in <cell line: 1>\n    pred = conv_net(x_train, weights, biases)\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_21060\\3236224927.py\", line 6, in conv_net\n    conv1 = maxpool2d(conv1, k=2)\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_21060\\1805355015.py\", line 8, in maxpool2d\n    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1082, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 4800, in max_pool_v2\n    return op(\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1082, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 5030, in max_pool2d\n    return gen_nn_ops.max_pool(\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 5386, in max_pool\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 740, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3776, in _create_op_internal\n    ret = Operation(\n  File \"D:\\Anaconda_2\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2175, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "# pred = conv_net(x_train, weights, biases)\n",
    "\n",
    "# cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "\n",
    "# # optimizer =  tf.optimizers.Adam(learning_rate=learning_rate) #.minimize(cost, var_list=[list(weights),list(biases)])\n",
    "# optimizer = tf1.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "# #calculate accuracy across all the given images and average them out.\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# init = tf1.global_variables_initializer()\n",
    "\n",
    "training_iters = 30\n",
    "batch_size = 128\n",
    "with tf1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    # summary_writer = tf1.summary.FileWriter('./Output', sess.graph)\n",
    "    for i in range(training_iters):\n",
    "        for batch in range(128):# range(len(x_train)//batch_size):\n",
    "            batch_x = x_train[batch*batch_size:min((batch+1)*batch_size,x_train.shape[0])]\n",
    "            batch_y = y_train[batch*batch_size:min((batch+1)*batch_size,y_train.shape[0])]    \n",
    "            # Run optimization op (backprop).\n",
    "                # Calculate batch loss and accuracy\n",
    "            input()\n",
    "            opt = sess.run(optimizer, feed_dict={x: batch_x.eval(),y: batch_y})\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x.eval(),\n",
    "                                                              y: batch_y})\n",
    "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        # Calculate accuracy for all 10000 mnist test images\n",
    "        test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: x_test,y : y_test})\n",
    "        train_loss.append(loss)\n",
    "        test_loss.append(valid_loss)\n",
    "        train_accuracy.append(acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "    # summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imp 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#net = NeuralNewtwork(10,100,11)\n",
    "#10 features for each example\n",
    "#11 classes for each example\n",
    "#100 unit in the hidden layer\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.L = len(layers)\n",
    "        self.num_features = layers[0]\n",
    "        self.num_classes = layers[-1]\n",
    "        \n",
    "        self.W = {}\n",
    "        self.b = {}\n",
    "        \n",
    "        self.dW = {}\n",
    "        self.db = {}\n",
    "        \n",
    "        self.setup()\n",
    "        \n",
    "    def setup(self):\n",
    "       \n",
    "        for i in range(1, self.L):\n",
    "            self.W[i] = tf.Variable(tf.random.normal(shape=(self.layers[i],self.layers[i-1])))\n",
    "            self.b[i] = tf.Variable(tf.random.normal(shape=(self.layers[i],1)))\n",
    "\n",
    "\n",
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def forward_pass(self, X):\n",
    "\n",
    "        A = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        for i in range(1, self.L):\n",
    "            Z = tf.matmul(A,tf.transpose(self.W[i])) + tf.transpose(self.b[i])\n",
    "            if i != self.L-1:\n",
    "                A = tf.nn.relu(Z)\n",
    "            else:\n",
    "                A = Z\n",
    "                input()\n",
    "        return A\n",
    "\n",
    "class NeuralNetwork(NeuralNetwork):\n",
    "\n",
    "    def compute_loss(self, A, Y):\n",
    "        print(\"compute_loss\")\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(Y,A)\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "    \n",
    "    def update_params(self, lr):\n",
    "        for i in range(1,self.L):\n",
    "            self.W[i].assign_sub(lr * self.dW[i])\n",
    "            self.b[i].assign_sub(lr * self.db[i])\n",
    "\n",
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def predict(self, X):\n",
    "\n",
    "        A = self.forward_pass(X)\n",
    "        return tf.argmax(tf.nn.softmax(A), axis=1)\n",
    "    \n",
    "    def info(self):\n",
    "        num_params = 0\n",
    "        for i in range(1, self.L):\n",
    "            num_params += self.W[i].shape[0] * self.W[i].shape[1]\n",
    "            num_params += self.b[i].shape[0]\n",
    "        print('Input Features:', self.num_features)\n",
    "        print('Number of Classes:', self.num_classes)\n",
    "        print('Hidden Layers:')\n",
    "        print('--------------')\n",
    "        for i in range(1, self.L-1):\n",
    "            print('Layer {}, Units {}'.format(i, self.layers[i]))\n",
    "        print('--------------')\n",
    "        print('Number of parameters:', num_params)\n",
    "\n",
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def train_on_batch(self, X, Y, lr):\n",
    "         \n",
    "        X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        Y = tf.convert_to_tensor(Y, dtype=tf.float32)\n",
    "          \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            print(\"Tape\")\n",
    "            A = self.forward_pass(X)\n",
    "            loss = self.compute_loss(A, Y)\n",
    "        for i in range(1, self.L):\n",
    "            print(f\"i: {i}\")\n",
    "\n",
    "            self.dW[i] = tape.gradient(loss, self.W[i])\n",
    "\n",
    "            # self.db[i] = tape.gradient(loss, self.b[i])\n",
    "        del tape\n",
    "        self.update_params(lr)\n",
    "        return loss.eval()#numpy()\n",
    "\n",
    "\n",
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def train(self, x_train, y_train, x_test, y_test, epochs, steps_per_epoch, batch_size, lr):\n",
    "\n",
    "        history = {\n",
    "            'val_loss':[],\n",
    "            'train_loss':[],\n",
    "            'val_acc':[]\n",
    "        }\n",
    "        \n",
    "        for e in range(0, epochs):\n",
    "            epoch_train_loss = 0.\n",
    "            print('Epoch{e}'.format(e), end='.')\n",
    "            for i in range(0, steps_per_epoch):\n",
    "                x_batch = x_train[i*batch_size:(i+1)*batch_size]\n",
    "                y_batch = y_train[i*batch_size:(i+1)*batch_size]\n",
    "                \n",
    "                batch_loss = self.train_on_batch(x_batch, y_batch,lr)\n",
    "                epoch_train_loss += batch_loss\n",
    "                \n",
    "                if i%int(steps_per_epoch/10) == 0:\n",
    "                    print(end='.')\n",
    "                    \n",
    "            history['train_loss'].append(epoch_train_loss/steps_per_epoch)\n",
    "            val_A = self.forward_pass(x_test)\n",
    "            val_loss = self.compute_loss(val_A, y_test).numpy()\n",
    "            history['val_loss'].append(val_loss)\n",
    "            val_preds = self.predict(x_test)\n",
    "            val_acc =    np.mean(np.argmax(y_test, axis=1) == val_preds.numpy())\n",
    "            history['val_acc'].append(val_acc)\n",
    "            print('Val acc:',val_acc)\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available(\n",
    "  cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork([784,128,128,10])\n",
    "net.info()\n",
    "(x_train, y_train, x_test, y_test) = preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 120\n",
    "epochs = 15\n",
    "steps_per_epoch = int(x_train.shape[0]/batch_size)\n",
    "lr = 3e-3\n",
    "print('Steps per epoch', steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   def model(data):\n",
    "#     conv1 = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "#     bias1 = tf.nn.relu(conv1 + layer1_biases)\n",
    "#     pool1 = tf.nn.max_pool(bias1, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "#     conv2 = tf.nn.conv2d(pool1, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "#     bias2 = tf.nn.relu(conv2 + layer2_biases)\n",
    "#     pool2 = tf.nn.max_pool(bias2, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "#     shape = pool2.get_shape().as_list()\n",
    "#     reshape = tf.reshape(pool2, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "#     hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "#     return tf.matmul(hidden, layer4_weights) + layer4_biases\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b26b377b6521054fae3a74a2f14cb9ee384f6c6757db04c797c5f4188bc4f62d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tf2.4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
